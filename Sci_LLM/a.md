## LLMs in science
### Models

|   Date    |     Name        | Publication | Repositories |
| :-------: | :-------------- | :---------- | :----------: |
| `2024.04` | DockingGA       | [DockingGA: enhancing targeted molecule generation using transformer neural network and genetic algorithm with docking simulation](https://academic.oup.com/bfg/advance-article-abstract/doi/10.1093/bfgp/elae011/7641743?redirectedFrom=fulltext&login=true) | |
| `2024.03` | BioMedLM        | [BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text](https://arxiv.org/abs/2403.18421) | [ðŸ¤—](https://huggingface.co/stanford-crfm/BioMedLM) |
| `2024.03` | TSMMG           | [Instruction Multi-Constraint Molecular Generation Using a Teacher-Student Large Language Model](https://arxiv.org/abs/2403.13244) |  |
| `2024.03` | 3M-Diffusion    | [3M-Diffusion: Latent Multi-Modal Diffusion for Text-Guided Generation of Molecular Graphs](https://arxiv.org/abs/2403.07179) | [![GitHub][github-icon]](https://github.com/huaishengzhu/3MDiffusion) |
| `2024.03` | MediSwift       | [MediSwift: Efficient Sparse Pre-trained Biomedical Language Models](https://arxiv.org/abs/2403.00952) |  |
| `2024.02` | BioT5+          | [BioT5+: Towards Generalized Biological Understanding with IUPAC Integration and Multi-task Tuning](https://arxiv.org/abs/2402.17810) | [![GitHub][github-icon]](https://github.com/QizhiPei/BioT5) |
| `2024.02` | BiMediX         | [BiMediX: Bilingual Medical Mixture of Experts LLM](https://arxiv.org/abs/2402.13253) | [github-icon](https://github.com/mbzuai-oryx/BiMediX) |

<!-- Image reference definition -->
[github-icon]: <img src="../assets/github.svg" width="20" />
